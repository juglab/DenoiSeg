{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenoiSeg Example: Mouse Nuclei\n",
    "This is an example notebook which illustrates how DenoiSeg should be trained. In this notebook we use nuclei dataset from a mouse skull from our collaborators. We already split the data into train and test images. From the train images we then extracted 908 training and 160 validation patches of size 128x128. The test set contains 67 images of size 256x256."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are just importing some libraries which are needed to run this notebook.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "from denoiseg.models import DenoiSeg, DenoiSegConfig\n",
    "from denoiseg.utils.misc_utils import combine_train_test_data, shuffle_train_data, augment_data\n",
    "from denoiseg.utils.seg_utils import *\n",
    "from denoiseg.utils.compute_precision_threshold import measure_precision\n",
    "\n",
    "from csbdeep.utils import plot_history\n",
    "\n",
    "import urllib\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and  Data Loading\n",
    "We created three versions of this dataset by adding Gaussian noise with zero mean and standard deviations 10 and 20. The dataset are marked with the suffixes n0, n10 and n20 accordingly.\n",
    "\n",
    "In the next cell you can choose which `noise_level` you would like to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the noise level you would like to look at:\n",
    "# Values: 'n0', 'n10', 'n20'\n",
    "noise_level = 'n20'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a folder for our data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "if noise_level == 'n0':\n",
    "    link = 'https://owncloud.mpi-cbg.de/index.php/s/nU9apzMYnEw7quC/download'\n",
    "elif noise_level == 'n10':\n",
    "    link = 'https://owncloud.mpi-cbg.de/index.php/s/hKf1AgVgD2RnPMN/download'\n",
    "elif noise_level == 'n20':\n",
    "    link = 'https://owncloud.mpi-cbg.de/index.php/s/7of6cBqyiecFBTj/download'\n",
    "else:\n",
    "    print('This noise level does not exist for this dataset.')\n",
    "\n",
    "# check if data has been downloaded already\n",
    "zipPath=\"data/Mouse_{}.zip\".format(noise_level)\n",
    "if not os.path.exists(zipPath):\n",
    "    #download and unzip data\n",
    "    data = urllib.request.urlretrieve(link, zipPath)\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading of the training images\n",
    "trainval_data =  np.load('data/Mouse_{}/train/train_data.npz'.format(noise_level))\n",
    "train_images = trainval_data['X_train'].astype(np.float32)\n",
    "train_masks = trainval_data['Y_train']\n",
    "val_images = trainval_data['X_val'].astype(np.float32)\n",
    "val_masks = trainval_data['Y_val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data =  np.load('data/Mouse_{}/test/test_data.npz'.format(noise_level))\n",
    "test_images = test_data['X_test'].astype(np.float32)\n",
    "test_masks = test_data['Y_test']\n",
    "plt.imshow(test_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of train_images: {}\".format(train_images.shape))\n",
    "print(\"Shape of train_masks:  {}\".format(train_masks.shape))\n",
    "print(\"Shape of val_images:   {}\".format(val_images.shape))\n",
    "print(\"Shape of val_masks:    {}\".format(val_masks.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Amounts of Annotated Training Data\n",
    "With DenoiSeg we present a solution to train deep neural networks if only few annotated ground truth segmentations are available. We simulate such a scenario by zeroing out all but a fraction of the available training data. In the next cell you can specify the percentage of training images for which ground truth annotations are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of annotated training images.\n",
    "# Values: 0.0 (no annotated images) to total number of training images (all images have annotations)\n",
    "number_of_annotated_training_images = 38\n",
    "assert number_of_annotated_training_images >= 0.0 and number_of_annotated_training_images <=train_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seed to shuffle training data (annotated GT and raw image pairs).\n",
    "seed = 1 \n",
    "\n",
    "# First we shuffle the training images to remove any bias.\n",
    "X_shuffled, Y_shuffled = shuffle_train_data(train_images, train_masks, random_seed=seed)\n",
    "\n",
    "# Here we convert the number of annotated images to be used for training as percentage of available training data.\n",
    "percentage_of_annotated_training_images = float((number_of_annotated_training_images/train_images.shape[0])*100.0)\n",
    "assert percentage_of_annotated_training_images >= 0.0 and percentage_of_annotated_training_images <=100.0\n",
    "\n",
    "# Here we zero out all training images which are not part of the \n",
    "# selected percentage.\n",
    "X_frac, Y_frac = zero_out_train_data(X_shuffled, Y_shuffled, fraction = percentage_of_annotated_training_images)\n",
    "\n",
    "# Now we apply data augmentation to the training patches:\n",
    "# Rotate four times by 90 degree and add flipped versions.\n",
    "X, Y_train_masks = augment_data(X_frac, Y_frac)\n",
    "X_val, Y_val_masks = val_images, val_masks\n",
    "\n",
    "# Here we add the channel dimension to our input images.\n",
    "# Dimensionality for training has to be 'SYXC' (Sample, Y-Dimension, X-Dimension, Channel)\n",
    "X = X[...,np.newaxis]\n",
    "Y = convert_to_oneHot(Y_train_masks)\n",
    "X_val = X_val[...,np.newaxis]\n",
    "Y_val = convert_to_oneHot(Y_val_masks)\n",
    "print(\"Shape of X:     {}\".format(X.shape))\n",
    "print(\"Shape of Y:     {}\".format(Y.shape))\n",
    "print(\"Shape of X_val: {}\".format(X_val.shape))\n",
    "print(\"Shape of Y_val: {}\".format(Y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we look at a single sample. In the first column we show the input image, in the second column the background segmentation, in the third column the foreground segmentation and in the last column the border segmentation.\n",
    "\n",
    "With the parameter `sample` you can choose different training patches. You will notice that not all of them have a segmentation ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = 0\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,4,1)\n",
    "plt.imshow(X[sample,...,0])\n",
    "plt.axis('off')\n",
    "plt.title('Raw validation image')\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(Y[sample,...,0], vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('1-hot encoded background')\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(Y[sample,...,1], vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('1-hot encoded foreground')\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(Y[sample,...,2], vmin=0, vmax=1, interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.title('1-hot encoded border');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 128\n",
    "train_steps_per_epoch = max(100, min(int(X.shape[0]/train_batch_size), 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### In the next cell, you can choose how much relative importance (weight) to assign to denoising \n",
    "### and segmentation tasks by choosing appropriate value for denoiseg_alpha (between 0 and 1; with 0 being\n",
    "### only segmentation and 1 being only denoising. Here we choose denoiseg_alpha = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = DenoiSegConfig(X, unet_kern_size=3, n_channel_out=4, relative_weights = [1.0,1.0,5.0],\n",
    "                      train_steps_per_epoch=train_steps_per_epoch, train_epochs=200, \n",
    "                      batch_norm=True, train_batch_size=128, unet_n_first = 32, \n",
    "                      unet_n_depth=4, denoiseg_alpha=0.5, train_tensorboard=False)\n",
    "\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_name = 'DenoiSeg_Mouse_n20'\n",
    "basedir = 'models'\n",
    "model = DenoiSeg(conf, model_name, basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.train(X, Y, (X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history, ['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Threshold Value\n",
    "The network predicts 4 output channels:\n",
    "1. The denoised input.\n",
    "2. The foreground likelihoods.\n",
    "3. The background likelihoods.\n",
    "4. The border likelihoods.\n",
    "\n",
    "We will threshold the foreground prediction image to obtain object segmentations. The optimal threshold is determined on the validation data. Additionally we can optimize the threshold for a given measure. In this case we choose the Average Precision (AP) measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold, val_score = model.optimize_thresholds(val_images.astype(np.float32), val_masks, measure=measure_precision())\n",
    "\n",
    "print(\"The higest score of {} is achieved with threshold = {}.\".format(np.round(val_score, 3), threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data\n",
    "Finally we load the test data and run the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data =  np.load('data/Mouse_{}/test/test_data.npz'.format(noise_level), allow_pickle=True)\n",
    "test_images = test_data['X_test']\n",
    "test_masks = test_data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_images, precision_result = model.predict_label_masks(test_images, test_masks, threshold, \n",
    "                                                                   measure=measure_precision())\n",
    "print(\"Average precision over all test images with threshold = {} is {}.\".format(threshold, np.round(precision_result, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sl = 0\n",
    "fig = plt.figure()\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_images[sl])\n",
    "plt.title(\"Raw image\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(predicted_images[sl])\n",
    "plt.title(\"Predicted segmentation\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(test_masks[sl])\n",
    "plt.title(\"Ground truth segmentation\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of annotated images used for training:\", number_of_annotated_training_images)\n",
    "print(\"Noise level:\", noise_level)\n",
    "print(\"Considered alpha:\", conf.denoiseg_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected results for this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>AP scores for Mouse n0 dataset</b>\n",
    "\n",
    "||5 imgs|10 imgs|19 imgs|38 imgs|76 imgs|\n",
    "|--- |--- |--- |--- |--- |--- |\n",
    "|Alpha 0.5|0.414±0.034|0.432±0.021|0.516±0.005|0.523±0.011|0.544±0.006|\n",
    "|Alpha 0.3|0.433±0.021|0.453±0.022|0.507±0.009|0.513±0.017|0.552±0.008|\n",
    "|Alpha 0.7|0.437±0.021|0.403±0.018|0.506±0.013|0.539±0.004|0.540±0.011|\n",
    "|Alpha best|0.462±0.019|0.484±0.020|0.539±0.003|0.546±0.004|0.571±0.003|\n",
    "\n",
    "<b>AP scores for Mouse n10 dataset</b>\n",
    "\n",
    "||5 imgs|10 imgs|19 imgs|38 imgs|76 imgs|\n",
    "|--- |--- |--- |--- |--- |--- |\n",
    "|Alpha 0.5|0.449±0.025|0.491±0.025|0.515±0.007|0.534±0.010|0.559±0.009|\n",
    "|Alpha 0.3|0.458±0.021|0.462±0.025|0.502±0.009|0.513±0.009|0.561±0.009|\n",
    "|Alpha 0.7|0.423±0.014|0.439±0.027|0.529±0.006|0.544±0.007|0.569±0.008|\n",
    "|Alpha best|0.497±0.021|0.502±0.023|0.558±0.002|0.558±0.006|0.586±0.006|\n",
    "\n",
    "<b>AP scores for Mouse n20 dataset</b>\n",
    "\n",
    "||5 imgs|10 imgs|19 imgs|38 imgs|76 imgs|\n",
    "|--- |--- |--- |--- |--- |--- |\n",
    "|Alpha 0.5|0.489±0.023|0.495±0.023|0.541±0.011|0.553±0.011|0.560±0.006|\n",
    "|Alpha 0.3|0.477±0.022|0.465±0.031|0.523±0.006|0.529±0.010|0.545±0.005|\n",
    "|Alpha 0.7|0.449±0.008|0.481±0.022|0.533±0.011|0.560±0.007|0.581±0.004|\n",
    "|Alpha best|0.538±0.011|0.524±0.020|0.562±0.004|0.571±0.004|0.591±0.006|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export your model for Fiji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.export_TF(name='DenoiSeg - Mouse Nuclei Example', \n",
    "                description='This is the 2D DenoiSeg example trained on Mouse Nuclei data in python.', \n",
    "                authors=[\"Tim-Oliver Buchholz\", \"Mangal Prakash\", \"Alexander Krull\", \"Florian Jug\"],\n",
    "                test_img=X_val[0,...,0], axes='YX',\n",
    "                patch_shape=(128, 128))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "denoiseg",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
