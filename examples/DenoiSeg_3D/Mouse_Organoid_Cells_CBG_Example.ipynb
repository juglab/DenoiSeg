{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenoiSeg Example: Mouse Organoid Cell\n",
    "This is an example notebook which illustrates how DenoiSeg should be trained. In this notebook we use a membrane labeled Mouse Organoid dataset from our collaborators. We already split the data into 86 train and 22 validation volumes. We will train a model on pathes of size 32x64x64 and we will do prediction on the validation set using original image size of 32x128x128."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Define parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 1000\n",
    "\n",
    "# Values: 0.0 (no annotated images) to total number of training images (all images have annotations)\n",
    "number_of_annotated_training_images = 7\n",
    "\n",
    "# We added artificial noise to the data to make it more challenging to segment and to showcase the \n",
    "# denoising capabilities of the model. Here you can choose 2 presaved levels, n10 or n20 \n",
    "noise_level = 'n20'\n",
    "\n",
    "train_batch_size = 4\n",
    "\n",
    "model_name = 'DenoiSeg_Mouse_Organoid_3D'\n",
    "basedir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Here we are just importing some libraries which are needed to run this notebook.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import math\n",
    "import urllib\n",
    "import zipfile\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from denoiseg.models import DenoiSeg, DenoiSegConfig\n",
    "from denoiseg.utils.misc_utils import combine_train_test_data, shuffle_train_data, augment_data, add_noise, split_train_test_data\n",
    "from denoiseg.utils.seg_utils import *\n",
    "from denoiseg.utils.compute_precision_threshold import measure_precision\n",
    "from denoiseg.utils.denoiseg_data_preprocessing import generate_patches_from_list\n",
    "\n",
    "from csbdeep.utils import plot_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Downloading and preparing data\n",
    "In the next cells you download training dataset with the level of noise defined by `noise_level` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create a folder for our data\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('data')\n",
    "\n",
    "if noise_level == 'n10':\n",
    "    link = 'https://download.fht.org/jug/denoiseg/Mouse-Organoid-Cells-CBG-128_n10.zip'\n",
    "elif noise_level == 'n20':\n",
    "    link = 'https://download.fht.org/jug/denoiseg/Mouse-Organoid-Cells-CBG-128_n20.zip'\n",
    "else:\n",
    "    print('This noise level does not exist for this dataset.')\n",
    "\n",
    "# check if data has been downloaded already\n",
    "zipPath = 'data/Mouse-Organoid-Cells-CBG-128_{}.zip'.format(noise_level)\n",
    "if not os.path.exists(zipPath):\n",
    "    data = urllib.request.urlretrieve(link, zipPath)\n",
    "\n",
    "#unzip the files\n",
    "if not os.path.exists(zipPath[:-4]):\n",
    "    with zipfile.ZipFile(zipPath, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = np.load(os.path.join(zipPath[:-8], 'train_data_{}.npz'.format(noise_level)))\n",
    "val = np.load(os.path.join(zipPath[:-8], 'test_data_{}.npz'.format(noise_level)))\n",
    "\n",
    "c = 10\n",
    "X, Y = train['X_train'][:c, ...], train['Y_train'][:c, ...]\n",
    "X_val, Y_val = val['X_test'][:c, ...], val['Y_test'][:c, ...]\n",
    "\n",
    "print(\"Shape of Train volume:      {}\".format(X.shape))\n",
    "print(\"Shape of Train mask:        {}\".format(Y.shape))\n",
    "print(\"Shape of Validation volume: {}\".format(X_val.shape))\n",
    "print(\"Shape of Validation mask:   {}\".format(Y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_annotated_training_images = float((number_of_annotated_training_images/X.shape[0])*100.0)\n",
    "assert percentage_of_annotated_training_images >= 0.0 and percentage_of_annotated_training_images <=100.0\n",
    "\n",
    "# Here we zero out all training images which are not part of the\n",
    "# selected percentage.\n",
    "X_frac, Y_frac = zero_out_train_data(X, Y, fraction=percentage_of_annotated_training_images)\n",
    "\n",
    "# Here we generate patches from images and apply augmentation\n",
    "X_final, Y_final = generate_patches_from_list([X_frac], [Y_frac], augment=True, shuffle=False, shape=(32, 64, 64))\n",
    "X_val_final, Y_val_final = generate_patches_from_list([X_val], [Y_val], augment=False, shape=(32, 64, 64))\n",
    "\n",
    "X_final = X_final[... ,np.newaxis]\n",
    "Y_final = convert_to_oneHot(Y_final, n_classes=3)\n",
    "\n",
    "X_val_final = X_val_final[... ,np.newaxis]\n",
    "Y_val_final = convert_to_oneHot(Y_val_final, n_classes=3)\n",
    "\n",
    "print(\"Shape of Train volume:      {}\".format(X_final.shape))\n",
    "print(\"Shape of Train mask:        {}\".format(Y_final.shape))\n",
    "print(\"Shape of Validation volume: {}\".format(X_val_final.shape))\n",
    "print(\"Shape of Validation mask:   {}\".format(Y_val_final.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D visualization[optional]\n",
    "For 3D visualization to be representative we resize the volume according to dataset's voxel(ZYX) size of [1.0, 0.1733, 0.1733] um. You may want to adjust the brighness level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install itkwidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itkwidgets import view, compare\n",
    "\n",
    "# Here we resize the volume for visualization purposes\n",
    "X_resized_3d = ndimage.zoom(X[0], (3.8468, 1, 1), order=0)\n",
    "view(X_resized_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of raw data and overlaid masks (2D views on 3D data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Number of training sample to be visualized\n",
    "sample_number = 0\n",
    "\n",
    "# Set the first and the last slice to show. The default setting will visualize 8 middle slices.\n",
    "slide_range = (12, 20)\n",
    "\n",
    "sample_image = X[sample_number, slide_range[0]:slide_range[1], ...]\n",
    "sample_mask = Y[sample_number, slide_range[0]:slide_range[1], ...]\n",
    "\n",
    "nrows = int(np.ceil(math.sqrt(sample_image.shape[0])))\n",
    "ncols = int(np.floor(math.sqrt(sample_image.shape[0])))\n",
    "\n",
    "_, axes = plt.subplots(int(np.ceil(sample_image.shape[0] / 2)), 1, figsize=(30,60))\n",
    "for i, ax in zip(range(sample_image.shape[0]), axes.flat):\n",
    "    ax.imshow(sample_image[i, :, :], cmap='bone')\n",
    "    ax.imshow(sample_mask[i, :, :], cmap='tab20', alpha=0.2)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Augment the data\n",
    "Augmentation will increase the number of images by the factor of 8, adding flips and 90 degree rotations. One-hot encoding may take a couple of minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize images/masks/borders\n",
    "You can set the range to visualize all frames or some part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of training sample to be visualized\n",
    "sample_number = 0\n",
    "\n",
    "# Set the first and the last slice to show. The default setting will visualize 8 middle slices.\n",
    "slide_range = (12, 20)\n",
    "\n",
    "aug_sample_image = X_final[sample_number, slide_range[0]:slide_range[1], ...]\n",
    "aug_sample_mask = Y_final[sample_number, slide_range[0]:slide_range[1], ...]\n",
    "\n",
    "# You may have to adjust figsize according to the number of slices\n",
    "fig, axes = plt.subplots(aug_sample_image.shape[0], 4, figsize=(30,80))\n",
    "for i, ax in zip(range(aug_sample_image.shape[0] * 4), axes.flat):\n",
    "    if i % 4 == 0:\n",
    "        ax.imshow(aug_sample_image[i // 4], cmap='bone')\n",
    "        ax.set_title('Noisy image', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    elif i % 4 == 1:\n",
    "        ax.imshow(aug_sample_mask[i // 4, ..., (i % 4) - 1], cmap='bone')\n",
    "        ax.set_title('Background mask', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    elif i % 4 == 2:\n",
    "        ax.imshow(aug_sample_mask[i // 4, ..., (i % 4) - 1], cmap='bone')\n",
    "        ax.set_title('Foreground mask', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    elif i % 4 == 3:\n",
    "        ax.imshow(aug_sample_mask[i // 4, ..., (i % 4) - 1], cmap='bone')\n",
    "        ax.set_title('Border mask', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Configure the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_steps_per_epoch = min(400, max(int(X_final.shape[0]/train_batch_size), 10))\n",
    "\n",
    "conf = DenoiSegConfig(X_final,\n",
    "                      unet_kern_size=3,\n",
    "                      n_channel_in=1,\n",
    "                      n_channel_out=4,\n",
    "                      relative_weights=[1.0,1.0,5.0],\n",
    "                      train_steps_per_epoch=train_steps_per_epoch,\n",
    "                      train_epochs=20,\n",
    "                      batch_norm=True,\n",
    "                      train_batch_size=train_batch_size,\n",
    "                      unet_n_first=32,\n",
    "                      unet_n_depth=4,\n",
    "                      denoiseg_alpha=0.5,\n",
    "                      n2v_patch_shape=(32, 64, 64),\n",
    "                      n2v_patch_size=(32, 64, 64),\n",
    "                      train_tensorboard=False)\n",
    "\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = DenoiSeg(conf, model_name, basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.train(X_final, Y_final, (X_val_final, Y_val_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_history(history, ['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Computing Threshold Value\n",
    "The network predicts 4 output channels:\n",
    "The denoised input.\n",
    "The foreground likelihoods.\n",
    "The background likelihoods.\n",
    "The border likelihoods.\n",
    "We will threshold the foreground prediction image to obtain object segmentations. The optimal threshold is determined on the validation data. Additionally we can optimize the threshold for a given measure. In this case we choose the Average Precision (AP) measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "threshold, val_score = model.optimize_thresholds(X_val.astype(np.float32),\n",
    "                                                 Y_val,\n",
    "                                                 measure=measure_precision(),\n",
    "                                                 axes='ZYX'\n",
    "                                                 )\n",
    "\n",
    "print(\"The highest score of {} is achieved with threshold = {}.\".format(np.round(val_score, 3), threshold))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Prediction\n",
    "Because of limited number of samples in the dataset we do prediction on validation data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predicted_denoised, predicted_images, precision_result, predicted_binary = model.predict_denoised_label_masks(X_val.astype(np.float32),\n",
    "                                                                                                              Y_val,\n",
    "                                                                                                              axes='ZYX',\n",
    "                                                                                                              threshold=threshold,\n",
    "                                                                                                              measure=measure_precision()\n",
    "                                                                                                             )\n",
    "print(\"Average precision over all test images with threshold = {} is {}.\".format(threshold, np.round(precision_result, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize denoised 3D volume\n",
    "Here we resize the volume for visualization purposes, with regard to downsized Y and X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_3d = ndimage.zoom(X_val[0].squeeze(), (3.8468, 1, 1), order=0)\n",
    "predicted_resized_3d = ndimage.zoom(predicted_denoised[0].squeeze(), (3.8468, 1, 1), order=0)\n",
    "compare(original_3d, predicted_resized_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize predicted masks in 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mask_3d = ndimage.zoom(Y_val[0].squeeze(), (3.8468, 1, 1), order=0)\n",
    "predicted_mask_3d = ndimage.zoom(predicted_images[0].squeeze(), (3.8468, 1, 1), order=0)\n",
    "compare(gt_mask_3d, predicted_mask_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_number = 1\n",
    "slide_range = (12, 20)\n",
    "\n",
    "original_image = X_val[sample_number, slide_range[0]:slide_range[1], ...]\n",
    "predicted_denoised_image = predicted_denoised[sample_number][slide_range[0]:slide_range[1], ...]\n",
    "predicted_mask = predicted_images[sample_number][slide_range[0]:slide_range[1], ...]\n",
    "predicted_binary_mask = predicted_binary[sample_number][slide_range[0]:slide_range[1], ...]\n",
    "gt_mask = Y_val[sample_number, slide_range[0]:slide_range[1], ...]\n",
    "\n",
    "\n",
    "_, axes = plt.subplots(predicted_mask.shape[0], 5, figsize=(30,80))\n",
    "for i, ax in zip(range(predicted_mask.shape[0] * 5), axes.flat):\n",
    "    if i % 5 == 0:\n",
    "        ax.imshow(original_image[i // 5], cmap='bone')\n",
    "        ax.set_title('Original noisy Image', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    elif i % 5 == 1:\n",
    "        ax.imshow(predicted_denoised_image[i // 5], cmap='bone')\n",
    "        ax.set_title('Denoised Image', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    elif i % 5 == 2:\n",
    "        ax.imshow(predicted_binary_mask[i // 5], cmap='bone')\n",
    "        ax.set_title('Predicted_binary mask', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    elif i % 5 == 3:\n",
    "        ax.imshow(predicted_mask[i // 5], cmap='tab20')\n",
    "        ax.set_title('Predicted mask', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "    else:\n",
    "        ax.imshow(gt_mask[i // 5, ...], cmap='tab20')\n",
    "        ax.set_title('Ground truth mask', fontdict={'fontsize': 18, 'fontweight': 'medium'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('denoiSeg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7f3ca4a47665ae5a48ccba64e08c2a0649ec5f9e27402eb1a290b7fd2e65ff71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
